{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NFT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divydividivu/DeepLearning.ai-Notes/blob/main/NFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFcNR8Bzybvm",
        "outputId": "d514a436-b6cd-4b63-9290-52e74c60eb60"
      },
      "source": [
        "# Importing all the header files\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, models, datasets\n",
        "import copy\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU is true')\n",
        "    print('cuda version: {}'.format(torch.version.cuda))\n",
        "else:\n",
        "    print('CPU is true')\n",
        "\n",
        "seed = 3\n",
        "torch.manual_seed(seed) \n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is true\n",
            "cuda version: 10.2\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShA-o5B-yuCs"
      },
      "source": [
        "train_bmp2 = os.path.join('/content/gdrive/MyDrive/MSTAR Dataset/MSTAR_PUBLIC_TARGETS_CHIPS_T72_BMP2_BTR70_SLICY/TARGETS/TRAIN/17_DEG/BMP2')\n",
        "train_btr70 = os.path.join('/content/gdrive/MyDrive/MSTAR Dataset/MSTAR_PUBLIC_TARGETS_CHIPS_T72_BMP2_BTR70_SLICY/TARGETS/TRAIN/17_DEG/BTR70')\n",
        "train_t72 = os.path.join('/content/gdrive/MyDrive/MSTAR Dataset/MSTAR_PUBLIC_TARGETS_CHIPS_T72_BMP2_BTR70_SLICY/TARGETS/TRAIN/17_DEG/T72')\n",
        "\n",
        "test_bmp2 = os.path.join('/content/gdrive/MyDrive/MSTAR Dataset/MSTAR_PUBLIC_TARGETS_CHIPS_T72_BMP2_BTR70_SLICY/TARGETS/TEST/15_DEG/BMP2')\n",
        "test_btr70 = os.path.join('/content/gdrive/MyDrive/MSTAR Dataset/MSTAR_PUBLIC_TARGETS_CHIPS_T72_BMP2_BTR70_SLICY/TARGETS/TEST/15_DEG/BTR70')\n",
        "test_t72 = os.path.join('/content/gdrive/MyDrive/MSTAR Dataset/MSTAR_PUBLIC_TARGETS_CHIPS_T72_BMP2_BTR70_SLICY/TARGETS/TEST/15_DEG/T72')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_XzDJkfdEaW"
      },
      "source": [
        "label_name = ['BMP2', 'BTR70, T72']\n",
        "train_img = []\n",
        "train_label = []\n",
        "\n",
        "for subclass in os.listdir(train_bmp2):\n",
        "    for file in os.listdir(train_bmp2 + '/' + subclass):    \n",
        "        image = cv2.imread(train_bmp2 + '/' + subclass + '/' + file, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.fastNlMeansDenoising(image, None, 15, 7, 21)\n",
        "        image = cv2.resize(image, (158, 158))\n",
        "        train_img.append(image)\n",
        "        train_label.append([1,0,0])\n",
        "\n",
        "for subclass in os.listdir(train_btr70):\n",
        "    for file in os.listdir(train_btr70 + '/' + subclass):    \n",
        "        image = cv2.imread(train_btr70 + '/' + subclass + '/' + file, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.fastNlMeansDenoising(image, None, 15, 7, 21)\n",
        "        image = cv2.resize(image, (158, 158))\n",
        "        train_img.append(image)\n",
        "        train_label.append([0,1,0])\n",
        "\n",
        "for subclass in os.listdir(train_t72):\n",
        "    for file in os.listdir(train_t72 + '/' + subclass):    \n",
        "        image = cv2.imread(train_t72 + '/' + subclass + '/' + file, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.fastNlMeansDenoising(image, None, 15, 7, 21)\n",
        "        image = cv2.resize(image, (158, 158))\n",
        "        train_img.append(image)\n",
        "        train_label.append([0,0,1])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rL5BLjo8tw9"
      },
      "source": [
        "num_epochs = 15\n",
        "num_classes = 3\n",
        "batch_size = 32\n",
        "learning_rate = 3e-4"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hic6nU-CmYpS"
      },
      "source": [
        "train_img = np.array(train_img)\n",
        "train_label = np.array(train_label)\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, img, label, transform=None):\n",
        "        super(MyDataset,self).__init__()       \n",
        "        self.img = torch.from_numpy(img).float()\n",
        "        self.label = torch.from_numpy(label).long()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index): \n",
        "        img = self.img[index]\n",
        "        label = self.label[index]\n",
        "        return img,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.img.shape[0]\n",
        "\n",
        "train_dataset = MyDataset(img=train_img,label=train_label, transform=transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ARG6QZuSuK",
        "outputId": "bd6fbed6-c4a4-4faf-c28c-1aca300af370"
      },
      "source": [
        "for i, (images, labels) in enumerate(train_loader): \n",
        "    print(images.shape)\n",
        "    print(i)\n",
        "    break\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 158, 158])\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQhmpkebCcjA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}